{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CWIntroductionToAI.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IntroductionToAICW/CW/blob/main/preprocessing/textPreprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWdXThqEW0k_"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSOfINGeuxPr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db75310c-c04b-472c-9cb4-6b23b9166a46"
      },
      "source": [
        "!pip install contractions\n",
        "!pip install langdetect"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: contractions in /usr/local/lib/python3.6/dist-packages (0.0.43)\n",
            "Requirement already satisfied: textsearch in /usr/local/lib/python3.6/dist-packages (from contractions) (0.0.17)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.6/dist-packages (from textsearch->contractions) (1.4.0)\n",
            "Requirement already satisfied: Unidecode in /usr/local/lib/python3.6/dist-packages (from textsearch->contractions) (1.1.2)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.6/dist-packages (1.0.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from langdetect) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGsTeJzNDYdf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "841eb722-3589-454a-ec63-b3c3be25af03"
      },
      "source": [
        "import pandas as pd\n",
        "import unicodedata\n",
        "from bs4 import BeautifulSoup\n",
        "import contractions\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "import gensim\n",
        "\n",
        "from nltk.corpus import twitter_samples \n",
        "nltk.download('twitter_samples')\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import LancasterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "import langdetect \n",
        "import time"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XztBsKMwWvYl"
      },
      "source": [
        "# Load datatasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzZi6A8h2U4n"
      },
      "source": [
        "You don't need to be connected to the drive to run the text preprocessing file, but you need it to store the output and to run the algorithms."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9XsiP-EuEHh"
      },
      "source": [
        "'''\n",
        "for the purpose of the cw and to be able to run our code efficiently and fast we created an email address in order to store our data there\n",
        "email: introtoaicw@gmail.com\n",
        "pass : Intro2020\n",
        "'''\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLYtgsA13sbq"
      },
      "source": [
        "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
        "all_negative_tweets = twitter_samples.strings('negative_tweets.json')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FC220wX0pNpH"
      },
      "source": [
        "negLabel = []\n",
        "posLabel = []\n",
        "for i in range(0, 5000):\n",
        "  negLabel.append(0)\n",
        "  posLabel.append(1)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ho0c-nFApn1e"
      },
      "source": [
        "labels = posLabel + negLabel"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNh6Jj1ECux8"
      },
      "source": [
        "tempTweet = all_positive_tweets + all_negative_tweets"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0tVJk63pLVf"
      },
      "source": [
        "data = {'text':tempTweet, 'labels':labels} "
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bX-ccI1T4igq"
      },
      "source": [
        "df = pd.DataFrame(data) "
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbxyD6XSkGrQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b779a743-f87a-4bdb-9742-ab0c9af18fb3"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   text    10000 non-null  object\n",
            " 1   labels  10000 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 156.4+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQUSFSyfqdWQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "01fd0015-ae11-48fb-969b-a3a5d29eb477"
      },
      "source": [
        "df"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>#FollowFriday @France_Inte @PKuchly57 @Milipol...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@Lamb2ja Hey James! How odd :/ Please call our...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@DespiteOfficial we had a listen last night :)...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@97sides CONGRATS :)</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>yeaaaah yippppy!!!  my accnt verified rqst has...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>I wanna change my avi but uSanele :(</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>MY PUPPY BROKE HER FOOT :(</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>where's all the jaebum baby pictures :((</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>But but Mr Ahmad Maslan cooks too :( https://t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>@eawoman As a Hull supporter I am expecting a ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  labels\n",
              "0     #FollowFriday @France_Inte @PKuchly57 @Milipol...       1\n",
              "1     @Lamb2ja Hey James! How odd :/ Please call our...       1\n",
              "2     @DespiteOfficial we had a listen last night :)...       1\n",
              "3                                  @97sides CONGRATS :)       1\n",
              "4     yeaaaah yippppy!!!  my accnt verified rqst has...       1\n",
              "...                                                 ...     ...\n",
              "9995               I wanna change my avi but uSanele :(       0\n",
              "9996                         MY PUPPY BROKE HER FOOT :(       0\n",
              "9997           where's all the jaebum baby pictures :((       0\n",
              "9998  But but Mr Ahmad Maslan cooks too :( https://t...       0\n",
              "9999  @eawoman As a Hull supporter I am expecting a ...       0\n",
              "\n",
              "[10000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IP1_86t_p4OS"
      },
      "source": [
        "# Language distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yudSTyu7ecjI"
      },
      "source": [
        "df['lang'] = df[\"text\"].apply(lambda x: langdetect.detect(x) if x.strip() != \"\" else \"\")"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkmLPbTVlSCL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "a40698aa-377d-4c1d-f62f-db5dc4919d49"
      },
      "source": [
        "# we do this to make sure that we don't have any other language in our dataframe\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = \"lang\"\n",
        "fig, ax = plt.subplots()\n",
        "fig.suptitle(x, fontsize=12)\n",
        "df[x].reset_index().groupby(x).count().sort_values(by= \n",
        "       \"index\").plot(kind=\"barh\", legend=False, \n",
        "        ax=ax).grid(axis='x')\n",
        "plt.show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GatCVDqYWdNj"
      },
      "source": [
        "# Steps of text Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__qehjyMUhVU"
      },
      "source": [
        "## HTML tags removal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PA9ssqqioceo"
      },
      "source": [
        "df[\"NoHTML_text\"] = df[\"text\"].map(lambda x: BeautifulSoup(x, \"html.parser\").get_text(separator = ' '))"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xwj-MbF3UjbB"
      },
      "source": [
        "## Non-ASCII and \\n \\r removal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hCYBHVdqdgi"
      },
      "source": [
        "df[\"ASCII_NoHTML_text\"] = df[\"NoHTML_text\"].str.encode(encoding = \"ascii\", errors=\"replace\").str.decode(encoding = \"utf-8\", errors=\"replace\")\n",
        "df[\"ASCII_NoHTML_text\"] = df[\"ASCII_NoHTML_text\"].map(lambda x: x.replace(\"\\r\", \" \"))\n",
        "df[\"ASCII_NoHTML_text\"] = df[\"ASCII_NoHTML_text\"].map(lambda x: x.replace(\"\\n\", \" \"))"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLAS5C_UUmWs"
      },
      "source": [
        "## Contractions expanding (strictly needed before lowercasing, punctuation and stopwords removal)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-EoOciaqoTm"
      },
      "source": [
        "df[\"ASCII_NoHTML_text\"] = df[\"ASCII_NoHTML_text\"].map(lambda x:contractions.fix(x)) "
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gwnrlq9uEo4H"
      },
      "source": [
        "## Email addresses removal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LlNrwYWEpTy"
      },
      "source": [
        "df[\"ASCII_NoHTML_text\"] = df[\"ASCII_NoHTML_text\"].map(lambda x: re.sub(r'\\S+@\\S+', ' ', x))"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCncxA7cD2JH"
      },
      "source": [
        "## Remove all the urls (www/http)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anYvKIN9DscD"
      },
      "source": [
        "df[\"ASCII_NoHTML_text\"] = df[\"ASCII_NoHTML_text\"].map(lambda x: re.sub(r'http\\S+', ' ', x))\n",
        "df[\"ASCII_NoHTML_text\"] = df[\"ASCII_NoHTML_text\"].map(lambda x: re.sub(r'www\\S+', ' ', x))"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jqj0x6lyUzNF"
      },
      "source": [
        "## Lowercasing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oSm6tWOq5vq"
      },
      "source": [
        "df[\"ASCII_NoHTML_text\"] = df[\"ASCII_NoHTML_text\"].str.lower()"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlPab55hgje2"
      },
      "source": [
        "## Punctuation removal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MYu01CxGp-C"
      },
      "source": [
        "list_punctuation= list(string.punctuation)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rM5ksgcIF6aC"
      },
      "source": [
        "def remove_punctuations(text):\n",
        "    text = str(text)\n",
        "    for punctuation in list_punctuation:\n",
        "        text = text.replace(punctuation, ' ')\n",
        "    return text"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDpGVBEwl4cQ"
      },
      "source": [
        "df['ASCII_NoHTML_text'] = df['ASCII_NoHTML_text'].map(remove_punctuations)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrvPIU5Ngje5"
      },
      "source": [
        "## Digits removal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-X-9biRU_7Ej"
      },
      "source": [
        "df[\"ASCII_NoHTML_text\"] = df[\"ASCII_NoHTML_text\"].str.replace('\\d+', '')"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IK-15IVWgje8"
      },
      "source": [
        "## Lemmatisation and Pos\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTBKrrfiAJ3L"
      },
      "source": [
        "#return Wordnet's POS tag from NLTK's POS tag, for each to-be-lemmatised token \n",
        "#in order to provide it as parameter at Wordnet's lemmatizer() function so that it performs lemmatisation based on the correct POS tag format of the word in the emails\n",
        "#we need the below mapping NLTK to Wordnet POS tag mapping function because lemmatizer() accepts the POS tag/ lemma basis parameter in Wordnet's format\n",
        "def get_wordnet_pos(word):\n",
        "    \"\"\"Map NLTK's POS tag to first character Wordnet's lemmatize() accepts\"\"\"\n",
        "    #pos_tag(): get the POS tag for a given single word/ token/ list of tokens ; it accepts only a list even in case of single word/ token, this is why we insert the word in brackets []\n",
        "    #           returns also a list of two-size tuple of n (n=size of inserted list, n>=1) elements\n",
        "    #           1st slot of the tuple has the inserted token of the ith element of inserted list, and the 2nd slot its POS tag  regardless of the inserted list size \n",
        "    #[0][1][0]: based on the above, with the first [0] we get inside the tuple of the returned/ output list\n",
        "    #           with the [1] we get to the 2nd slot, thus the POS tag of the examined tuple\n",
        "    #           with the final [0] we hold only the first character of the POS tag as brought from NLTK\n",
        "    #.upper():  convert all lowercase characters in a string into uppercase characters; so that we are safe using only uppercase strings in mapping below\n",
        "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
        "    #mapping NLTK's first letter of POS tags (as brought from pos_tag() above) to the Wordnet POS tag format, which the POS tag format lemmatizer() accepts\n",
        "    tag_dict = {\"J\": wordnet.ADJ,\n",
        "                \"N\": wordnet.NOUN,\n",
        "                \"V\": wordnet.VERB,\n",
        "                \"R\": wordnet.ADV}\n",
        "    #return the tag_dict's 'value' of tag (tag_dict's 'key')\n",
        "    #wordnet.NOUN: optional parameter, a value to return ('n' POS tag in our case) if the specified 'key' (tag in our case) does not exist\n",
        "    return tag_dict.get(tag, wordnet.NOUN)\n",
        "\n",
        "#lemmatisation tries to convert a word to its meaningful base form/ lemma\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "#we use list comprehension again here, however without 'if' conditional as it is not needed\n",
        "#lemmatisation is performed on token so the token is provided as first parameter \n",
        "#and apart from the token itself we also provide as second parameter the (wordnet) POS tag of that token in order to provide for the lemmatizer function to learn the POS tag of the to-be-lemmatised token so the token is lemmatized correctly\n",
        "df[\"Lemma_NoSal_ASCII_NoHTML_text\"] = df[\"ASCII_NoHTML_text\"].map(lambda x: \" \".join([lemmatizer.lemmatize(word, get_wordnet_pos(word)) for word in word_tokenize(x)]))"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4cAXGh7gjfB"
      },
      "source": [
        "## Stopwords removal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuxLkkFJAZzC"
      },
      "source": [
        "#a\n",
        "#bring NLTK english stopwords\n",
        "NLTK_english_stopwords = stopwords.words(\"english\")\n",
        "#bring Gensim (english) stopwords (converting them to a list from a frozenset)\n",
        "#we need Gensim stopwords as well as it includes many missing from NLTK unimportant words (either, eg, etc, few, during and many others)\n",
        "Gensim_stopwords = list(gensim.parsing.preprocessing.STOPWORDS)\n",
        "#spacy.load('en_core_web_md')\n",
        "\n",
        "all_english_stopwords = NLTK_english_stopwords\n",
        "#join together NLTK english and Gensim stopwords into a single list\n",
        "all_english_stopwords.extend(Gensim_stopwords)\n",
        "#change the list to a set in order to get the unique values, thus get rid of duplicate words existing in both NLTK and Gensim\n",
        "all_english_stopwords = set(all_english_stopwords)\n",
        "#change the set back to list holding all default NLTK and Gensim unique stopwords\n",
        "all_english_stopwords = list(all_english_stopwords)\n",
        "all_english_stopwords.sort()\n",
        "\n",
        "#b\n",
        "#user manually added english stopwords ('re' not included because it is already included in the below stopwords lists)\n",
        "user_english_stopwords = []\n",
        "\n",
        "\n",
        "#alphabet list in order to exclude single characters\n",
        "english_alphabet = list(string.ascii_lowercase)\n",
        "user_english_stopwords.extend(english_alphabet)\n",
        "#bringing in a single list the [NLTK + Gensim] and [user defined stopwords + english alphabet]\n",
        "all_english_stopwords.extend(user_english_stopwords)\n",
        "#I want to hold negation stopwords as if bigrams are used (which according to an article are considered more powerful than unigrams)\n",
        "#then the meaning of the tweet is conpletely different with their inclusion\n",
        "#eg \"not good\" or \"not bug\" are different from \"good\", \"bug\" thus could also be categorised differently\n",
        "#If unigrams are used then maybe I think I should remove them; will decide on a later phase according to results\n",
        "negation_stopwords = [\"no\", \"not\"]\n",
        "all_english_stopwords = [word for word in all_english_stopwords if word not in negation_stopwords]\n",
        "\n",
        "#change the list to a set in order to get the unique values\n",
        "all_english_stopwords = set(all_english_stopwords)\n",
        "#change the set back to list holding all final stopwords\n",
        "all_english_stopwords = list(all_english_stopwords)\n",
        "all_english_stopwords.sort()\n",
        "\n",
        "df[\"NoSW_Lemma_NoSal_ASCII_NoHTML_text\"] = df[\"Lemma_NoSal_ASCII_NoHTML_text\"].map(lambda x: \" \".join([word for word in word_tokenize(x) if word not in (all_english_stopwords)]))"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_z6Q9yrYpCF"
      },
      "source": [
        "## Stemming"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4myJM_T7yTae"
      },
      "source": [
        "decide to not use stemming after analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBcE1vvjA_aI"
      },
      "source": [
        "# stemmer = LancasterStemmer()\n",
        "# df['Stem_NoSW_Lemma_NoSal_ASCII_NoHTML_text'] = df['NoSW_Lemma_NoSal_ASCII_NoHTML_text'].map(lambda x: \" \".join([stemmer.stem(word) for word in word_tokenize(x)]))"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zuB3DeWgjfI"
      },
      "source": [
        "## Hold only valid preprocessed emails"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cyIn61cBNHa"
      },
      "source": [
        "valid_df = df.loc[df[\"NoSW_Lemma_NoSal_ASCII_NoHTML_text\"].map(lambda x: len(x)!=0),].reset_index(drop=True)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRIYypxFMTAC"
      },
      "source": [
        "valid_df[\"afterProcess\"] = valid_df[\"NoSW_Lemma_NoSal_ASCII_NoHTML_text\"]\n",
        "valid_df['labels'] = df['labels']"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVZoF_QGBqRg"
      },
      "source": [
        "## Save file in a pickle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrrmhVp-BdUc",
        "outputId": "f7ec709e-3f9c-49a0-edf1-cf0347fd2850",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        }
      },
      "source": [
        "valid_df.to_pickle(\"/content/drive/My Drive/dataset/valid_df.pkl\")"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-6ee381af9551>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvalid_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/My Drive/dataset/testvalid_df.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_pickle\u001b[0;34m(self, path, compression, protocol)\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpickle\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2676\u001b[0;31m         \u001b[0mto_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2678\u001b[0m     def to_clipboard(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mto_pickle\u001b[0;34m(obj, filepath_or_buffer, compression, protocol)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcompression\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"infer\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mcompression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHIGHEST_PROTOCOL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors)\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/dataset/testvalid_df.pkl'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDFwANXxm5GO"
      },
      "source": [
        "valid_df[\"afterProcess\"]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}